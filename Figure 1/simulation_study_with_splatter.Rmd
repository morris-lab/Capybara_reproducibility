---
title: "Simulation Study with Splatter"
output: html_notebook
---

### Brief Description
In this notebook, we document the generation of the simulated single-cell dataset from a trajectory using Splatter (Zappia et al., Genome Biology, 2017). We use this simulated data to demonstrate the efficacy of Capybara to classify discrete, hybrid, unknown cells, and unknown progenitors. For simulation details, please refer to the Splatter paper (https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1305-0). For details of Capybara cell-type classification, please refer to the Capybara paper here (https://www.sciencedirect.com/science/article/pii/S1934590922000996?dgcid=coauthor).

### Load packages
```{r, warning=FALSE, message=FALSE}
library(splatter)
library(Capybara)
library(scater)
library(mixdist)
library(MASS)
require(pastecs)
```

### Load source functions
```{r}
### https://math.stackexchange.com/questions/453113/how-to-merge-two-gaussians
calculate.params <- function(fitted.params) {
  mu.est <- sum(fitted.params$parameters$mu * fitted.params$parameters$pi)
  var.num <- (fitted.params$parameters$sigma)^2 
  var.est <- sum(var.num * (fitted.params$parameters$pi)^2)
  
  return(list(mu.est, var.est))
}

model.estimation <- function(background) {
  d <- density(background)
  his <- hist(background, breaks = 100)
  
  df <- data.frame(mid=his$mids, cou=his$counts)
  ts_y <- ts(d$y)
  tp <- turnpoints(ts_y)
  guemea <- d$x[tp$peaks]
  guesig <- rep((max(df$mid) - min(df$mid))/4, length(guemea))
  
  guedis <- "norm"
  fitpro <- mix(as.mixdata(df), mixparam(mu=guemea, sigma=guesig))
  
  return(fitpro)
}

calculate.deviance.p.val <- function(deviance.df, centers.smu) {
  cell.types <- ncol(deviance.df) - 1
  sd.est <- (1/cell.types)/(cell.types - 1)
  deviance.df$p.val.single <- pnorm(deviance.df$total.deviance, mean = centers.smu$single.center, sd = sd.est)
  deviance.df$p.val.multi <- pnorm(deviance.df$total.deviance, mean = centers.smu$multi.center, sd = sd.est)
  deviance.df$p.val.unknown <- pnorm(deviance.df$total.deviance, mean = centers.smu$unknown.center, sd = sd.est)
  
  return(deviance.df)
}

calculate.deviance <- function(qp.test.mtx) {
  cell.types <- ncol(qp.test.mtx) - 2
  deviance.from.all <- abs(qp.test.mtx[,c(1:cell.types)] - 1/cell.types)
  deviance.from.all$total.deviance <- rowSums(deviance.from.all)
  
  return(deviance.from.all)
}

get.thresholds <- function(qp.test.mtx) {
  cell.types <- ncol(qp.test.mtx) - 2
  exp.score <- 1/cell.types
  ## single id thresholds
  single.id.th.top <- (1-exp.score) + (exp.score * (cell.types - 1))
  if (cell.types >= 3) {
    single.id.th.bottom <- (1/2-exp.score) * 2 + (exp.score * (cell.types - 2))
  } else {
    print("No Solid Evidence for Multi-ID! Check the QP scores for continuous measure!")
    single.id.th.bottom <- single.id.th.top
  }
  
  ## multi id thresholds
  multi.id.th.top <- (1/2-exp.score) * 2 + (exp.score * (cell.types - 2))
  if (cell.types > 3) {
    multi.id.th.bottom <- (1/3-exp.score) * 3 + (exp.score * (cell.types - 3))
  } else {
    multi.id.th.bottom <- multi.id.th.top
  }
  
  ## Unknown thresholds
  unknown.center <- 0
  
  return(list(single.center = mean(c(single.id.th.top)),
              multi.center = mean(c(multi.id.th.top, multi.id.th.bottom)),
              unknown.center = unknown.center))
}
```

### Simulation with Splatter
#### Parameter Setup
Here we will use the original parameters suggested by Splatter. We design the cell population to originate from a progenitor state (P1) bifurcating toward two discrete states (E1: End State #1; P2: Progenitor State #2). P2 progenitor cells bifurcate further toward end states #2 and #3 (E2 and E3, respectively).
 
```{r}
params <- newSplatParams(batchCells = 6000,
                         nGenes = 8000,
                         group.prob = c(0.25, 0.25, 0.25, 0.25),
                         path.from = c(0, 0, 2, 2),
                         path.nSteps = c(100, 100, 100, 100),
                         de.prob = 0.5,
                         de.facLoc = 0.3,
                         de.facScale = 0.6,
                         seed = 10)
params
```

#### Simulate the path data
1) Here we will use the above parameters to simulate the data and plot on a PCA components plot.
```{r}
sim.paths <- splatSimulate(params = params, method = "path")
sim.paths <- logNormCounts(sim.paths)
sim.paths <- runPCA(sim.paths)
plotPCA(sim.paths, colour_by = "Step")
plotPCA(sim.paths, colour_by = "Group")
```
2) Assess the meta data
```{r}
col.dt.path <- as.data.frame(colData(sim.paths))
head(col.dt.path)
```

3) Here, we subset the groups in preparation for Capybara processing. We construct the reference using three cell populations, including E1, P2 and E2. The differentiated cell populations are defined as within 5% variability of the maximum pseudotime. We take a look at the cell groups, including differentiated fates, progenitor state (P1), and the intermediate state between P2 and E2.
```{r}
cells.diff.names <- rownames(col.dt.path)[which(col.dt.path$Step >= 95)]
cells.p1.p2.ori <- rownames(col.dt.path)[which(col.dt.path$Step <= 10 & (col.dt.path$Group %in% c("Path1", "Path2")))]
cells.p2.p3.intermed <- rownames(col.dt.path)[which(col.dt.path$Step <= 55 & col.dt.path$Step > 45 & (col.dt.path$Group %in% c("Path3")))]
sim.paths.sub <- sim.paths[,c(cells.diff.names, cells.p1.p2.ori, cells.p2.p3.intermed)]
sim.paths.sub <- logNormCounts(sim.paths.sub)
sim.paths.sub <- runPCA(sim.paths.sub)
plotPCA(sim.paths.sub, colour_by = "Group")
```

### Capybara
#### Get Counts
Here we extract counts from the SingleCellExperiment object and label the different states.
```{r}
count.sim.path <- counts(sim.paths.sub)
col.path.sub <- as.data.frame(colData(sim.paths.sub))
col.path.sub$label[which(col.path.sub$Step <= 55 & col.path.sub$Step > 45)] <- "P3.Intermed"
col.path.sub$label[which(col.path.sub$Step <= 10)] <- "P1.P2.Origin"
col.path.sub$label[which(col.path.sub$Step >= 95)] <- paste0(col.path.sub$Group[which(col.path.sub$Step >= 95)], ".Term")
```

#### Reference Construction
1) Here we include E1, P2, E3 discrete identities to construct the reference. We generate the data frame for reference generation.
```{r}
col.dt.path.sub.term.ori <- col.path.sub[-which(col.path.sub$label %in% c("P1.P2.Origin", "P3.Intermed", "Path4.Term")), ]
```

2) Using the Metadata above with the counts data, we construct the high-resolution reference.
```{r, warning=FALSE}
ref.dt.path <- construct.high.res.reference(count.sim.path, col.dt.path.sub.term.ori, "label")
ref.sc.path <- ref.dt.path[[1]]
ref.meta.path <- ref.dt.path[[2]]
ref.df.path <- ref.dt.path[[3]]
```

#### Test Set Construction
Here we generate a test set for this dataset using the remaining cells that were not included in the reference.
```{r}
test.remaining.cells.path <- setdiff(rownames(col.path.sub), ref.dt.path[[2]]$cell.bc)
test.count.set.path <- count.sim.path[,test.remaining.cells.path]
```

#### Run Quadratic Programming
```{r}
# Measure cell identity in the reference dataset as a background 
single.round.QP.analysis(ref.df.path, ref.sc.path, n.cores = 2, save.to.path = "~/Desktop/Reproducibility/Figure 1/", save.to.filename = "01_simulated_data_reference", force.eq = 1, unix.par = TRUE)

# Measure cell identity in the query dataset 
single.round.QP.analysis(ref.df.path, test.count.set.path, n.cores = 2, save.to.path = "~/Desktop/Reproducibility/Figure 1/", save.to.filename = "01_simulated_data_sample", unix.par = TRUE, force.eq = 1)
```

#### Empirical p-value calculation
```{r}
# Read in background and testing identity scores
background.mtx <- read.csv("~/Desktop/Reproducibility/Figure 1/01_simulated_data_reference_scale.csv", header = T, row.names = 1, stringsAsFactors = F)
mtx.test <- read.csv("~/Desktop/Reproducibility/Figure 1/01_simulated_data_sample_scale.csv", header = T, row.names = 1, stringsAsFactors = F)

col.sub <- ncol(background.mtx) - 2

# Conduct reference randomization to get empirical p-value matrix
ref.perc.list <- percentage.calc(background.mtx[,c(1:col.sub)], background.mtx[,c(1:col.sub)])

# Conduct test randomization to get empirical p-value matrix
perc.list <- percentage.calc(as.matrix(mtx.test[,c(1:col.sub)]), as.matrix(background.mtx[,c(1:col.sub)]))
```

#### Initial Classification
Here we perform initial classification based on the quadratic programming metrics: deviance, error, and lagrangian multipliers. Deviance the main metric used to distinguish unknown cells from discrete and hybrid cells. Error and Lagrangian multipliers are used to further distinguish the unknown terminal cell identities from unknown progenitors.

1) Calculate Deviance and background
```{r}
deviance.from.all <- calculate.deviance(mtx.test)
centers.diff.id <- get.thresholds(mtx.test)
deviance.from.all <- calculate.deviance.p.val(deviance.from.all, centers.diff.id)
```

2) Compute Error and Lagrangian Multiplier Distribution
```{r}
error.all.new <- mtx.test[,c(4,5)]
model.fit.err <- model.estimation(background.mtx$Error)
model.fit.lm <- model.estimation(background.mtx$Lagrangian)

err.params <- calculate.params(model.fit.err)
lm.params <- calculate.params(model.fit.lm)

error.all.new$p.values.lm.mode <- pnorm(error.all.new$Lagrangian, mean = lm.params[[1]], sd = sqrt(lm.params[[2]]), lower.tail = F)
error.all.new$p.values.lm.lower <- pnorm(error.all.new$Lagrangian,  mean = lm.params[[1]], sd = sqrt(lm.params[[2]]), lower.tail = T)
error.all.new$p.values <- pnorm(error.all.new$Error,  mean = err.params[[1]], sd = sqrt(err.params[[2]]), lower.tail = F)
```

3) Based on deviance, we initially classify cells as unknown, discrete, or hybrid.
```{r}
init.class <- data.frame(cell.bc = rownames(deviance.from.all), init.class = "Unknown", stringsAsFactors = F)
rownames(init.class) <- init.class$cell.bc
#classification.path[rownames(error.path.all[which(error.path.all$deviance < 0.5), ]), "new.classification.4"] <- "Unknown_unknown_prog"
init.class[rownames(deviance.from.all[which(deviance.from.all$p.val.single >= 0.05), ]), "init.class"] <- "Single-ID"
init.class[rownames(deviance.from.all[which(deviance.from.all$p.val.multi > 0.05 & deviance.from.all$p.val.single < 0.01), ]), "init.class"] <- "Multi_ID"
init.class[rownames(deviance.from.all[which(deviance.from.all$p.val.unknown > 0 & deviance.from.all$p.val.multi < 0.05 & deviance.from.all$p.val.single <= 0.05), ]), "init.class"] <- "Unknown"
```

4) Further distinction unknown cells.

Note: use this analysis with caution as we could not distinguish unknown terminal cell identities from unknown progenitors with 100% accuracy.

```{r}
### further characterization
unknown.current <- rownames(init.class[which(init.class$init.class == "Unknown"), ])
init.class[intersect(unknown.current, rownames(error.all.new[which(error.all.new$p.values >= 0.05),])), "init.class"] <- "Unknown.Progenitor"
```

#### Binarization and Classification
1) We generate the binarization matrix so that unknown cells are labelled 0, unknown progenitors -1, and known cell types labelled 1.
```{r}
# Binarization of inference results
bin.count <- binarization.mann.whitney(mtx = mtx.test[,c(1:col.sub)], ref.perc.ls = ref.perc.list, ref.meta = ref.meta.path, perc.ls = perc.list, init.class = init.class)
```

2) Classification based on this binary count matrix
```{r}
classification.path <- binary.to.classification(bin.count[,c(1:col.sub)])
rownames(classification.path) <- classification.path$barcode
```

### Compare classification
1) We compare our classification with the original label. First, we add the actual labels into the same data frame.
```{r}
classification.path$actual <- col.path.sub[rownames(classification.path), "label"]
```

2) Construct the percentage agreement matrix for heatmap plotting
```{r}
rslt <- table(classification.path$call, classification.path$actual)
rslt <- as.data.frame(apply(rslt, 2, function(x) round(x * 100/sum(x), digits = 3)))
rownames(rslt) <- paste0("Capy.", rownames(rslt))
colnames(rslt) <- paste0("Actual.", colnames(rslt))
rslt$capy <- rownames(rslt)
rslt.stk <- reshape2::melt(rslt)
```

3) Plot heatmaps with ggplot
```{r}
rslt.stk$capy <- factor(rslt.stk$capy, levels = c("Capy.Unknown.Progenitor", "Capy.Multi_ID",
                                                  "Capy.Path1.Term", "Capy.Path2.Term", "Capy.Path3.Term",
                                                  "Capy.Unknown"), ordered = T)
rslt.stk$variable <- factor(rslt.stk$variable, levels = c("Actual.P1.P2.Origin", "Actual.P3.Intermed",
                                                  "Actual.Path1.Term", "Actual.Path2.Term", "Actual.Path3.Term",
                                                  "Actual.Path4.Term"), ordered = T)
ggplot(rslt.stk, aes(x = variable, y = capy, fill = value)) +
  geom_tile() +
  scale_fill_viridis_c(begin = 0.15, end = 0.85, option = "A") +
  labs(x = "Actual Annotation", y = "Capybara Annotation") +
  ggtitle("Simulation Classification Result") +
  theme(legend.position="right",
        axis.text.x = element_text(face = "bold.italic", size = 12, angle = 45, hjust = 1),
        axis.text.y = element_text(face = "bold.italic", size = 12),
        axis.title = element_text(face = "bold.italic", size = 14), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        title = element_text(face = "bold.italic", size = 14),
        axis.line = element_line(colour = "black", size = 0.5),
        axis.ticks = element_blank())
```



